{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zghoJNCmGAQY"
      },
      "source": [
        "# 装包以及初始化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH_o5pZM0pUj",
        "outputId": "f4f736ca-54a8-49c7-8b5e-32130b2255fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: langchain in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (0.0.281)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (0.0.33)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: openai in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tiktoken in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from tiktoken) (2023.8.8)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: unstructured in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (0.10.12)\n",
            "Requirement already satisfied: chardet in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (4.9.3)\n",
            "Requirement already satisfied: nltk in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (4.12.2)\n",
            "Requirement already satisfied: emoji in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (2.8.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from unstructured) (0.5.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from dataclasses-json->unstructured) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: click in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from nltk->unstructured) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from nltk->unstructured) (2023.8.8)\n",
            "Requirement already satisfied: tqdm in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from nltk->unstructured) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->unstructured) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->unstructured) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->unstructured) (2023.7.22)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (4.7.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: chromadb in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (0.4.9)\n",
            "Requirement already satisfied: requests>=2.28 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.9 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (1.10.12)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (0.7.2)\n",
            "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (0.99.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (0.23.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (4.7.1)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (1.15.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (0.14.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (4.66.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (7.4.0)\n",
            "Requirement already satisfied: importlib-resources in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from chromadb) (1.25.2)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from fastapi<0.100.0,>=0.95.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: coloredlogs in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.3)\n",
            "Requirement already satisfied: sympy in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: six>=1.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
            "Requirement already satisfied: huggingface_hub<0.17,>=0.16.4 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from tokenizers>=0.13.2->chromadb) (0.16.4)\n",
            "Requirement already satisfied: click>=7.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from importlib-resources->chromadb) (3.16.2)\n",
            "Requirement already satisfied: filelock in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.3)\n",
            "Requirement already satisfied: fsspec in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (4.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pinecone-client in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pinecone-client) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pinecone-client) (6.0.1)\n",
            "Requirement already satisfied: loguru>=0.5.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pinecone-client) (0.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pinecone-client) (4.7.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pinecone-client) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pinecone-client) (2.0.4)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pinecone-client) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting ipywidgets\n",
            "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/b8/d4/ce436660098b2f456e2b8fdf76d4f33cbc3766c874c4aa2f772c7a5e943f/ipywidgets-8.1.0-py3-none-any.whl.metadata\n",
            "  Downloading ipywidgets-8.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: comm>=0.1.3 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipywidgets) (0.1.4)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipywidgets) (8.15.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipywidgets) (5.9.0)\n",
            "Collecting widgetsnbextension~=4.0.7 (from ipywidgets)\n",
            "  Obtaining dependency information for widgetsnbextension~=4.0.7 from https://files.pythonhosted.org/packages/8e/d4/d31b12ac0b87e8cc9fdb6ea1eb6596de405eaaa2f25606aaa755d0eebbc0/widgetsnbextension-4.0.8-py3-none-any.whl.metadata\n",
            "  Downloading widgetsnbextension-4.0.8-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab-widgets~=3.0.7 (from ipywidgets)\n",
            "  Obtaining dependency information for jupyterlab-widgets~=3.0.7 from https://files.pythonhosted.org/packages/74/5e/2475ac62faf2e342b2bf20b8d8e375f49400ecb38f52e4e0a7557eb1cedb/jupyterlab_widgets-3.0.8-py3-none-any.whl.metadata\n",
            "  Downloading jupyterlab_widgets-3.0.8-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: backcall in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: decorator in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
            "Requirement already satisfied: matplotlib-inline in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
            "Requirement already satisfied: stack-data in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: appnope in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
            "Requirement already satisfied: executing>=1.2.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
            "Requirement already satisfied: pure-eval in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
            "Downloading ipywidgets-8.1.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m0m\n",
            "\u001b[?25hDownloading jupyterlab_widgets-3.0.8-py3-none-any.whl (214 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.8-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
            "Successfully installed ipywidgets-8.1.0 jupyterlab-widgets-3.0.8 widgetsnbextension-4.0.8\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: youtube-transcript-api in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (0.6.1)\n",
            "Requirement already satisfied: requests in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->youtube-transcript-api) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->youtube-transcript-api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->youtube-transcript-api) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->youtube-transcript-api) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: google-search-results in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->google-search-results) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->google-search-results) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->google-search-results) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages (from requests->google-search-results) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv\n",
        "%pip install langchain\n",
        "%pip install openai\n",
        "%pip install tiktoken\n",
        "%pip install unstructured\n",
        "%pip install chromadb\n",
        "%pip install pinecone-client\n",
        "%pip install ipywidgets\n",
        "%pip install youtube-transcript-api\n",
        "%pip install google-search-results\n",
        "# %pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlXsg0mqEKsU",
        "outputId": "07611667-0216-4e93-b348-e05c11e4d5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "azure\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(dotenv_path=\"./config/.env\")\n",
        "print(os.environ[\"OPENAI_API_TYPE\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao78SDEp1Xbf"
      },
      "source": [
        "# 使用 LangChain 完成一次问答"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSeOZmGJ1aL_",
        "outputId": "7c32a9b9-b617-4c55-fcad-cb1bb8167011"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='人工智能是一种具有革命性潜力的技术，它可以模拟和实现人类智能的某些能力。人工智能在许多领域都展现出了巨大的潜力和应用前景。\\n\\n首先，人工智能在解决复杂问题和进行大数据分析方面具有独特的优势。通过机器学习和深度学习等技术，人工智能可以从大量的数据中提取有价值的信息，并进行预测和决策。这在医疗诊断、金融风险评估、智能交通等领域具有重要意义。\\n\\n其次，人工智能能够提供更加个性化和智能化的服务。通过对用户的行为和偏好进行分析，人工智能可以为用户量身定制推荐内容，提供更好的用户体验。例如，智能助手可以根据用户的日常习惯和喜好提供个性化的建议和服务。\\n\\n然而，人工智能也存在一些挑战和问题。首先，人工智能的发展需要大量的数据支持，但数据隐私和安全问题也日益突出。此外，人工智能的决策过程往往是黑盒子，难以解释和理解。这给人们带来了隐私和伦理方面的担忧。\\n\\n总体来说，人工智能是一项具有巨大潜力和广阔前景的技术，它能够为人类社会带来巨大的改变和进步。然而，我们也需要谨慎对待人工智能的发展，积极探索如何最大限度地发挥其优势，同时解决其带来的问题和挑战。', additional_kwargs={}, example=False)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        ")\n",
        "msg = HumanMessage(content=\"怎么评价人工智能\")\n",
        "llm(messages=[msg])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0-Zs6KZ6Dgi"
      },
      "source": [
        "# 通过 Google 搜索并返回答案"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfyZF-aW6RJa",
        "outputId": "6a26fa1c-d425-4c9c-e04b-94c3583e93dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI can use the search engine to find the current date and search for historical events that have taken place on this day.\n",
            "Action: Search\n",
            "Action Input: \"current date\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Current Time (World Clock) and online and printable Calendars for countries worldwide. Find the best time for web meetings (Meeting Planner) or use the Time ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThis search result doesn't provide the current date. I should try a different search query.\n",
            "Action: Search\n",
            "Action Input: \"current date\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Current Time (World Clock) and online and printable Calendars for countries worldwide. Find the best time for web meetings (Meeting Planner) or use the Time ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThis search result still doesn't provide the current date. I should try a different search query.\n",
            "Action: Search\n",
            "Action Input: \"today's date\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[\"Today's date is… Wednesday, September 13, 2023. Today's date in mm/dd/yyyy format: 09/13/2023.\"]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the current date. I can now search for historical events that have taken place on this day.\n",
            "Action: Search\n",
            "Action Input: \"historical events on September 13\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'National Hispanic Heritage Month', 'date': {'start_date': 'Sep 1', 'when': 'Sep 1 – 30, 2024'}, 'address': ['United States', 'United States'], 'link': 'https://www.google.com/search?oq=historical+events+on+September+13&q=historical+events+on+September+13&gl=us&sourceid=chrome&hl=en&ibp=htl;events&rciv=evn&sa=X&ved=2ahUKEwj-9fTTo6yBAxXGEVkFHQ2CDzYQ5bwDegQISBAB#fpstate=tldetail&htidocid=L2F1dGhvcml0eS9ob3Jpem9uL2NsdXN0ZXJlZF9ldmVudC8yMDIyLTA5LTAxfF8xMjE1MTI3MzA5Nzc3NjI3MTg4Nw%3D%3D&htivrt=events&mid=/g/11rq4gl_bv', 'thumbnail': 'https://serpapi.com/searches/6504209aaa6c959988b1aab2/images/4fbdb76aa3751b1d1dcf270e71f5413ccca0b7a274879733c20cba522647330e.png'}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have found a historical event that took place on September 13. It is National Hispanic Heritage Month, which runs from September 1 to September 30, 2024. \n",
            "\n",
            "Thought: I now know the final answer.\n",
            "Final Answer: Today's date is September 13, 2023. One historical event that has taken place on this day is the start of National Hispanic Heritage Month.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Today's date is September 13, 2023. One historical event that has taken place on this day is the start of National Hispanic Heritage Month.\""
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "# 加载 AzureChatOpenAI 模型\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    temperature=0,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        " # 加载 serpapi 工具\n",
        "tools = load_tools([\"serpapi\"])\n",
        "# 工具加载后都需要初始化，verbose 参数为 True，会打印全部的执行详情\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# 运行 agent\n",
        "agent.run(\"What's the date today? What great events have taken place today in history?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1nWOkGvCStj"
      },
      "source": [
        "# 对超长文本进行总结"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WriJqBU6RDa",
        "outputId": "92b45cef-320c-4c65-f547-53e138ce48d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "documents:1\n",
            "documents:7\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Write a concise summary of the following in Traditional Chinese:\n",
            "------------\n",
            "魯鎭的酒店的格局，是和別處不同的：都是當街一個曲尺形的大櫃臺，櫃裏面豫備着熱水，可以隨時溫酒。做工的人，傍午傍晚散了工，每每花四文銅錢，買一碗酒，——這是二十多年前的事，現在每碗要漲到十文，——靠櫃外站着，熱熱的喝了休息；倘肯多花一文，便可以買一碟鹽煮筍，或者茴香豆，做下酒物了，如果出到十幾文，那就能買一樣葷菜，但這些顧客，多是短衣幫，大抵沒有這樣闊綽。只有穿長衫的，纔踱進店面隔壁的房子裏，要酒要菜，慢慢地坐喝。\n",
            "\n",
            "我從十二歲起，便在鎭口的咸亨酒店裏當夥計，掌櫃說，樣子太傻，怕侍候不了長衫主顧，就在外面做點事罷。外面的短衣主顧，雖然容易說話，但嘮嘮叨叨纏夾不清的也很不少。他們往往要親眼看着黃酒從罎子裏舀出，看過壺子底裏有水沒有，又親看將壺子放在熱水裏，然後放心：在這嚴重監督下，羼水也很爲難。所以過了幾天，掌櫃又說我幹不了這事。幸虧薦頭的情面大，辭退不得，便改爲專管溫酒的一種無聊職務了。\n",
            "\n",
            "我從此便整天的站在櫃臺裏，專管我的職務。雖然沒有什麼失職，但總覺得有些單調，有些無聊。掌櫃是一副凶臉孔，主顧也沒有好聲氣，教人活潑不得；只有孔乙己到店，纔可以笑幾聲，所以至今還記得。\n",
            "------------\n",
            "CONCISE SUMMARY:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: This passage describes the layout and atmosphere of a hotel in Lu Town. It mentions the availability of hot water for warming wine and the option to purchase food alongside drinks. The narrator worked as an attendant at the hotel but was eventually assigned the monotonous task of warming wine. The narrator finds the job dull and the customers demanding, except for one customer named Kong Yiji who brings some laughter to the otherwise serious environment. Kong Yiji is the only person who stands while drinking and wears a long gown. He is tall with a pale face and scars on his wrinkled face. His beard is messy and gray. Although his long gown is dirty and torn, it hasn't been repaired or washed in over ten years. According to rumors, Kong Yiji was once educated but never pursued further education and lacks any practical skills. As a result, he became increasingly poor and was on the verge of begging. However, he had a talent for calligraphy and would exchange his written work for food. Unfortunately, he also had a bad habit of drinking too much and being lazy. Within a few days of his arrival, he would steal anything he could find, including books and writing materials. This behavior caused people to stop asking him to write for them. Kong Yiji had no choice but to occasionally resort to theft. However, his behavior in the hotel was better than others, as he never owed money and always paid off his debts promptly. Although he sometimes couldn't pay immediately, he would have it recorded on a slate, but within a month, he would always clear the debt. Kong Yiji drinks half a bowl of wine and his flushed face gradually returns to normal. Other people then ask him if he really knows how to read. Kong Yiji looks at them with a disdainful expression and they continue to mock him for not even being able to become a scholar. This immediately puts Kong Yiji in a state of melancholy and unease, and his face turns gray while he mutters words that no one understands. This causes everyone to burst into laughter, filling the atmosphere inside and outside the hotel with joy. The passage also reveals that the narrator can pretend to laugh along with the customers without being reprimanded by the manager. Kong Yiji often tries to engage in conversation with the customers, but they mock him and question his literacy skills. The narrator dismisses Kong Yiji's attempt to teach him how to write and leaves, causing Kong Yiji to express disappointment.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "孔乙己是站着喝酒而穿長衫的唯一的人。他身材很高大；青白臉色，皺紋間時常夾些傷痕；一部亂蓬蓬的花白的鬍子。穿的雖然是長衫，可是又髒又破，似乎十多年沒有補，也沒有洗。他對人說話，總是滿口之乎者也，教人半懂不懂的。因爲他姓孔，別人便從描紅紙上的「上大人孔乙己」這半懂不懂的話裏，替他取下一個綽號，叫作孔乙己。孔乙己一到店，所有喝酒的人便都看着他笑，有的叫道，「孔乙己，你臉上又添上新傷疤了！」他不回答，對櫃裏說，「溫兩碗酒，要一碟茴香豆。」便排出九文大錢。他們又故意的高聲嚷道，「你一定又偷了人家的東西了！」孔乙己睜大眼睛說，「你怎麼這樣憑空汚人清白……」「什麼清白？我前天親眼見你偷了何家的書，吊着打。」孔乙己便漲紅了臉，額上的青筋條條綻出，爭辯道，「竊書不能算偷……竊書！……讀書人的事，能算偷麼？」接連便是難懂的話，什麼「君子固窮」，什麼「者乎」之類，引得衆人都鬨笑起來：店內外充滿了快活的空氣。\n",
            "------------\n",
            "Given the new context, refine the original summary in Traditional Chinese.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: This passage describes the layout and atmosphere of a hotel in Lu Town. It mentions the availability of hot water for warming wine and the option to purchase food alongside drinks. The narrator worked as an attendant at the hotel but was eventually assigned the monotonous task of warming wine. The narrator finds the job dull and the customers demanding, except for one customer named Kong Yiji who brings some laughter to the otherwise serious environment. Kong Yiji is the only person who stands while drinking and wears a long gown. He is tall with a pale face and scars on his wrinkled face. His beard is messy and gray. Although his long gown is dirty and torn, it hasn't been repaired or washed in over ten years. According to rumors, Kong Yiji was once educated but never pursued further education and lacks any practical skills. As a result, he became increasingly poor and was on the verge of begging. However, he had a talent for calligraphy and would exchange his written work for food. Unfortunately, he also had a bad habit of drinking too much and being lazy. Within a few days of his arrival, he would steal anything he could find, including books and writing materials. This behavior caused people to stop asking him to write for them. Kong Yiji had no choice but to occasionally resort to theft. However, his behavior in the hotel was better than others, as he never owed money and always paid off his debts promptly. Although he sometimes couldn't pay immediately, he would have it recorded on a slate, but within a month, he would always clear the debt. Kong Yiji drinks half a bowl of wine and his flushed face gradually returns to normal. Other people then ask him if he really knows how to read. Kong Yiji looks at them with a disdainful expression and they continue to mock him for not even being able to become a scholar. This immediately puts Kong Yiji in a state of melancholy and unease, and his face turns gray while he mutters words that no one understands. This causes everyone to burst into laughter, filling the atmosphere inside and outside the hotel with joy. The passage also reveals that the narrator can pretend to laugh along with the customers without being reprimanded by the manager. Kong Yiji often tries to engage in conversation with the customers, but they mock him and question his literacy skills. The narrator dismisses Kong Yiji's attempt to teach him how to write and leaves, causing Kong Yiji to express disappointment.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "聽人家背地裏談論，孔乙己原來也讀過書，但終於沒有進學，又不會營生；於是愈過愈窮，弄到將要討飯了。幸而寫得一筆好字，便替人家鈔鈔書，換一碗飯吃。可惜他又有一樣壞脾氣，便是好喝懶做。坐不到幾天，便連人和書籍紙張筆硯，一齊失蹤。如是幾次，叫他鈔書的人也沒有了。孔乙己沒有法，便免不了偶然做些偷竊的事。但他在我們店裏，品行卻比別人都好，就是從不拖欠；雖然間或沒有現錢，暫時記在粉板上，但不出一月，定然還清，從粉板上拭去了孔乙己的名字。\n",
            "\n",
            "孔乙己喝過半碗酒，漲紅的臉色漸漸復了原，旁人便又問道，「孔乙己，你當眞認識字麼？」孔乙己看着問他的人，顯出不屑置辯的神氣。他們便接着說道，「你怎的連半個秀才也撈不到呢？」孔乙己立刻顯出頹唐不安模樣，臉上籠上了一層灰色，嘴裏說些話；這回可是全是之乎者也之類，一些不懂了。在這時候，衆人也都鬨笑起來：店內外充滿了快活的空氣。\n",
            "------------\n",
            "Given the new context, refine the original summary in Traditional Chinese.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'intermediate_steps': ['這段文字描述了魯鎮的一家酒店的情景，該酒店的格局和其他地方不同，有一個曲尺形的大櫃臺，裡面備有熱水可以溫酒。故事的主角是一個從十二歲起在這家酒店當夥計的人，他的工作是溫酒。他覺得這份工作單調無聊，只有當一位顧客叫做孔乙己的時候，他才能笑得開心。',\n",
              "  '這段敘述了盧鎮上一家旅店的佈局和氛圍。它提到了用來溫暖酒的熱水的可用性，以及在飲料旁邊購買食物的選項。敘述者曾在旅店擔任服務員，但最終被分派到單調的溫酒任務上。敘述者覺得這份工作乏味，顧客們要求苛刻，除了一位名叫孔乙己的顧客，他給原本嚴肅的環境帶來了一些笑聲。孔乙己是唯一一個站着喝酒並穿着長衫的人。他身材高大，臉色蒼白，皺紋上有傷痕。他的鬍子又亂又灰白。雖然他的長衫髒兮兮的，破爛不堪，已經十多年沒有補過也沒有洗過。據傳，孔乙己曾經受過教育，但從未繼續深造，缺乏實用技能。結果，他變得越來越窮，幾乎要行乞。然而，他擁有書法才華，可以用他的書寫作品換取食物。不幸的是，他也有喝酒過量和懶散的壞習慣。在他到達的幾天內，他會偷走他能找到的任何東西，包括書籍和寫作材料。這種行為使人們停止請他寫字。孔乙己別無選擇，只能偶爾訴諸偷竊。然而，他在旅店的行為比其他人好，他從不欠錢，總是及時償還債務。雖然有時他無法立即支付，但他會將其記錄在一塊石板上，但在一個月內，他總會清償債務。孔乙己喝了半碗酒，臉色漸漸恢復正常。其他人接著問他是否真的懂得讀書。孔乙己以輕蔑的表情看着他們，他們繼續嘲笑他連成為士人都不行。這立刻使孔乙己陷入憂鬱和不安的狀態，他的臉色變得灰暗，嘟囔出一些無人理解的話語。這引起了衆人的笑聲，使得旅店內外充滿了歡樂的氣氛。此外，這段還透露了敘述者可以假裝與顧客一起笑，而不會受到經理的責罰。孔乙己經常試圖與顧客交談，但他們嘲笑他，質疑他的識字能力。敘述者對孔乙己教他寫字的嘗試不以爲然，並離開，這使孔乙己表達了失望。',\n",
              "  '這節摘要描述了魯鎮上一家旅館的佈局和氛圍。它提到了供暖酒的熱水和可以在喝酒的同時購買食物的選項。敘述者曾在旅館擔任服務員，但最終被分配到單調的熱酒工作。敘述者覺得這份工作枯燥無味，顧客們也很苛刻，除了一位名叫孔乙己的顧客，他給這個本來嚴肅的環境帶來了一些笑聲。孔乙己是唯一一個站著喝酒並穿著長袍的人，他高大的身材，蒼白的臉上有著皺紋和傷疤。他的胡子凌亂而灰白，長袍雖然骯髒破爛，但十多年來既未修補也未洗滌。根據傳言，孔乙己曾受過教育，卻從未進一步深造，缺乏實用技能。結果，他變得越來越窮，幾乎要變成乞丐。然而，他擅長書法，會用自己寫的字換取食物。不幸的是，他還有喝酒過量和懶散的壞習慣。在他到達的幾天裏，他會偷走他能找到的任何東西，包括書籍和寫作材料。這種行為使人們停止請他寫字。孔乙己別無選擇，只能偶爾訴諸偷竊。然而，在旅館裏，他的行為比其他人都要好，從不欠錢，總是及時付清債務。雖然有時候他支付不了即時款項，但會在粉板上記錄下來，不過一個月內，他總能清償債務。孔乙己喝過半碗酒後，臉色漸漸恢復正常。其他人問他是否真的懂得讀書。孔乙己以輕蔑的表情看著他們，他們繼續嘲笑他連個秀才都做不成。這立刻讓孔乙己陷入了憂郁和不安的狀態，他的臉色變灰，嘴裏喃喃自語，沒有人能理解。這讓大家爆笑起來，旅館裏外充滿了歡樂的氛圍。文章還揭示了敘述者能夠假裝跟顧客一起笑，而不受經理的責罰。孔乙己經常試圖與顧客交談，但他們嘲笑他，質疑他的識字能力。敘述者對孔乙己想教他寫字的企圖不屑一顧，離開了，這讓孔乙己感到失望。'],\n",
              " 'output_text': '這節摘要描述了魯鎮上一家旅館的佈局和氛圍。它提到了供暖酒的熱水和可以在喝酒的同時購買食物的選項。敘述者曾在旅館擔任服務員，但最終被分配到單調的熱酒工作。敘述者覺得這份工作枯燥無味，顧客們也很苛刻，除了一位名叫孔乙己的顧客，他給這個本來嚴肅的環境帶來了一些笑聲。孔乙己是唯一一個站著喝酒並穿著長袍的人，他高大的身材，蒼白的臉上有著皺紋和傷疤。他的胡子凌亂而灰白，長袍雖然骯髒破爛，但十多年來既未修補也未洗滌。根據傳言，孔乙己曾受過教育，卻從未進一步深造，缺乏實用技能。結果，他變得越來越窮，幾乎要變成乞丐。然而，他擅長書法，會用自己寫的字換取食物。不幸的是，他還有喝酒過量和懶散的壞習慣。在他到達的幾天裏，他會偷走他能找到的任何東西，包括書籍和寫作材料。這種行為使人們停止請他寫字。孔乙己別無選擇，只能偶爾訴諸偷竊。然而，在旅館裏，他的行為比其他人都要好，從不欠錢，總是及時付清債務。雖然有時候他支付不了即時款項，但會在粉板上記錄下來，不過一個月內，他總能清償債務。孔乙己喝過半碗酒後，臉色漸漸恢復正常。其他人問他是否真的懂得讀書。孔乙己以輕蔑的表情看著他們，他們繼續嘲笑他連個秀才都做不成。這立刻讓孔乙己陷入了憂郁和不安的狀態，他的臉色變灰，嘴裏喃喃自語，沒有人能理解。這讓大家爆笑起來，旅館裏外充滿了歡樂的氛圍。文章還揭示了敘述者能夠假裝跟顧客一起笑，而不受經理的責罰。孔乙己經常試圖與顧客交談，但他們嘲笑他，質疑他的識字能力。敘述者對孔乙己想教他寫字的企圖不屑一顧，離開了，這讓孔乙己感到失望。'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "\n",
        "# 导入文本\n",
        "loader = TextLoader(\"./data/novel.txt\", encoding=\"utf8\")\n",
        "# 将文本转成 Document 对象\n",
        "document = loader.load()\n",
        "print(f'documents:{len(document)}')\n",
        "\n",
        "# 初始化文本分割器\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 0\n",
        ")\n",
        "\n",
        "# 切分文本\n",
        "split_documents = text_splitter.split_documents(document)\n",
        "print(f'documents:{len(split_documents)}')\n",
        "\n",
        "# 加载 llm 模型\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    max_tokens=1500,\n",
        ")\n",
        "\n",
        "# 创建自定义 prompt\n",
        "question_prompt_str = \"\"\"\n",
        "Write a concise summary of the following in Traditional Chinese:\n",
        "------------\n",
        "{text}\n",
        "------------\n",
        "CONCISE SUMMARY:\n",
        "\"\"\"\n",
        "question_prompt = PromptTemplate(template=question_prompt_str, input_variables=[\"text\"])\n",
        "\n",
        "refine_prompt_str = \"\"\"Your job is to produce a final summary.\n",
        "We have provided an existing summary up to a certain point: This passage describes the layout and atmosphere of a hotel in Lu Town. It mentions the availability of hot water for warming wine and the option to purchase food alongside drinks. The narrator worked as an attendant at the hotel but was eventually assigned the monotonous task of warming wine. The narrator finds the job dull and the customers demanding, except for one customer named Kong Yiji who brings some laughter to the otherwise serious environment. Kong Yiji is the only person who stands while drinking and wears a long gown. He is tall with a pale face and scars on his wrinkled face. His beard is messy and gray. Although his long gown is dirty and torn, it hasn't been repaired or washed in over ten years. According to rumors, Kong Yiji was once educated but never pursued further education and lacks any practical skills. As a result, he became increasingly poor and was on the verge of begging. However, he had a talent for calligraphy and would exchange his written work for food. Unfortunately, he also had a bad habit of drinking too much and being lazy. Within a few days of his arrival, he would steal anything he could find, including books and writing materials. This behavior caused people to stop asking him to write for them. Kong Yiji had no choice but to occasionally resort to theft. However, his behavior in the hotel was better than others, as he never owed money and always paid off his debts promptly. Although he sometimes couldn't pay immediately, he would have it recorded on a slate, but within a month, he would always clear the debt. Kong Yiji drinks half a bowl of wine and his flushed face gradually returns to normal. Other people then ask him if he really knows how to read. Kong Yiji looks at them with a disdainful expression and they continue to mock him for not even being able to become a scholar. This immediately puts Kong Yiji in a state of melancholy and unease, and his face turns gray while he mutters words that no one understands. This causes everyone to burst into laughter, filling the atmosphere inside and outside the hotel with joy. The passage also reveals that the narrator can pretend to laugh along with the customers without being reprimanded by the manager. Kong Yiji often tries to engage in conversation with the customers, but they mock him and question his literacy skills. The narrator dismisses Kong Yiji's attempt to teach him how to write and leaves, causing Kong Yiji to express disappointment.\n",
        "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
        "------------\n",
        "{text}\n",
        "------------\n",
        "Given the new context, refine the original summary in Traditional Chinese.\n",
        "If the context isn't useful, return the original summary.\"\"\"\n",
        "refine_prompt = PromptTemplate(template=refine_prompt_str, input_variables=[\"text\"])\n",
        "\n",
        "# 创建总结链\n",
        "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True, return_intermediate_steps=True, question_prompt=question_prompt, refine_prompt=refine_prompt)\n",
        "\n",
        "# 执行总结链，（为了快速演示，只总结前5段）\n",
        "chain({\"input_documents\": split_documents[:3]}, return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NySCEE0-tKw-"
      },
      "source": [
        "# 构建本地知识库问答机器人"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGoTRXA5tUbW",
        "outputId": "ef30f4b6-5c19-4cc2-a5dd-b18b09036080"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Created a chunk of size 208, which is longer than the specified 100\n",
            "Created a chunk of size 188, which is longer than the specified 100\n",
            "Created a chunk of size 398, which is longer than the specified 100\n",
            "Created a chunk of size 213, which is longer than the specified 100\n",
            "Created a chunk of size 160, which is longer than the specified 100\n",
            "Created a chunk of size 380, which is longer than the specified 100\n",
            "Created a chunk of size 142, which is longer than the specified 100\n",
            "Created a chunk of size 238, which is longer than the specified 100\n",
            "Created a chunk of size 450, which is longer than the specified 100\n",
            "/Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages/langchain/embeddings/openai.py:214: UserWarning: WARNING! deployment_name is not default parameter.\n",
            "                    deployment_name was transferred to model_kwargs.\n",
            "                    Please confirm that deployment_name is what you intended.\n",
            "  warnings.warn(\n",
            "/Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages/langchain/embeddings/openai.py:214: UserWarning: WARNING! model_name is not default parameter.\n",
            "                    model_name was transferred to model_kwargs.\n",
            "                    Please confirm that model_name is what you intended.\n",
            "  warnings.warn(\n",
            "/Users/jiyu/anaconda3/envs/learn/lib/python3.9/site-packages/langchain/chains/retrieval_qa/base.py:251: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': '孔乙己是谁？人们对他的评价是什么？', 'result': '孔乙己是一个身材高大、面色青白、穿着破烂的人。他喜欢站着喝酒，说话时常用一些令人难以理解的词语。人们从他的姓氏和红纸上的字句中，给他取了一个绰号叫孔乙己。他常常被人嘲笑和取笑，但他的到来却给大家带来了欢乐的气氛。虽然孔乙己读过书，但最终没有进学，也不会谋生，变得越来越贫困，甚至要讨饭。幸好他写字很好，可以为人抄书换取一碗饭。然而，他又有个坏习惯，喜欢喝酒懒于工作，经常偷窃。尽管如此，在店里，他的品行却比别人好，从不拖欠账务。即使偶尔没有现钱，暂时记在粉板上，但不到一个月就一定会还清，抹去孔乙己的名字。', 'source_documents': [Document(page_content='孔乙己是站着喝酒而穿長衫的唯一的人。他身材很高大；青白臉色，皺紋間時常夾些傷痕；一部亂蓬蓬的花白的鬍子。穿的雖然是長衫，可是又髒又破，似乎十多年沒有補，也沒有洗。他對人說話，總是滿口之乎者也，教人半懂不懂的。因爲他姓孔，別人便從描紅紙上的「上大人孔乙己」這半懂不懂的話裏，替他取下一個綽號，叫作孔乙己。孔乙己一到店，所有喝酒的人便都看着他笑，有的叫道，「孔乙己，你臉上又添上新傷疤了！」他不回答，對櫃裏說，「溫兩碗酒，要一碟茴香豆。」便排出九文大錢。他們又故意的高聲嚷道，「你一定又偷了人家的東西了！」孔乙己睜大眼睛說，「你怎麼這樣憑空汚人清白……」「什麼清白？我前天親眼見你偷了何家的書，吊着打。」孔乙己便漲紅了臉，額上的青筋條條綻出，爭辯道，「竊書不能算偷……竊書！……讀書人的事，能算偷麼？」接連便是難懂的話，什麼「君子固窮」，什麼「者乎」之類，引得衆人都鬨笑起來：店內外充滿了快活的空氣。', metadata={'source': 'data/novel.txt'}), Document(page_content='孔乙己是這樣的使人快活，可是沒有他，別人也便這麼過。', metadata={'source': 'data/novel.txt'}), Document(page_content='孔乙己喝過半碗酒，漲紅的臉色漸漸復了原，旁人便又問道，「孔乙己，你當眞認識字麼？」孔乙己看着問他的人，顯出不屑置辯的神氣。他們便接着說道，「你怎的連半個秀才也撈不到呢？」孔乙己立刻顯出頹唐不安模樣，臉上籠上了一層灰色，嘴裏說些話；這回可是全是之乎者也之類，一些不懂了。在這時候，衆人也都鬨笑起來：店內外充滿了快活的空氣。', metadata={'source': 'data/novel.txt'}), Document(page_content='聽人家背地裏談論，孔乙己原來也讀過書，但終於沒有進學，又不會營生；於是愈過愈窮，弄到將要討飯了。幸而寫得一筆好字，便替人家鈔鈔書，換一碗飯吃。可惜他又有一樣壞脾氣，便是好喝懶做。坐不到幾天，便連人和書籍紙張筆硯，一齊失蹤。如是幾次，叫他鈔書的人也沒有了。孔乙己沒有法，便免不了偶然做些偷竊的事。但他在我們店裏，品行卻比別人都好，就是從不拖欠；雖然間或沒有現錢，暫時記在粉板上，但不出一月，定然還清，從粉板上拭去了孔乙己的名字。', metadata={'source': 'data/novel.txt'})]}\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain import VectorDBQA\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# 加载文件夹中的所有txt类型的文件\n",
        "loader = DirectoryLoader('./data', glob='**/*.txt')\n",
        "# 将数据转成 document 对象，每个文件会作为一个 document\n",
        "documents = loader.load()\n",
        "\n",
        "# 初始化加载器\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "# 切割加载的 document\n",
        "split_documents = text_splitter.split_documents(documents)\n",
        "\n",
        "# 初始化 openai 的 embeddings 对象\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    deployment_name=\"text-embedding-ada-002\",\n",
        "    model_name=\"text-embedding-ada-002\",\n",
        "    chunk_size=1,\n",
        ")\n",
        "# 将 document 通过 openai 的 embeddings 对象计算 embedding向量信息并临时存入 Chroma 向量数据库，用于后续匹配查询\n",
        "docsearch = Chroma.from_documents(split_documents, embeddings)\n",
        "\n",
        "# 加载 llm 模型\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    max_tokens=1500,\n",
        ")\n",
        "# 创建问答对象\n",
        "qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch, return_source_documents=True)\n",
        "# 进行问答\n",
        "result = qa({\"query\": \"孔乙己是谁？人们对他的评价是什么？\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gGjGMljB24P"
      },
      "source": [
        "# 构建向量索引数据库"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "hSKnlX1AB-__",
        "outputId": "d4b5fa66-68fa-4fc1-dc92-81fdd764efa2"
      },
      "outputs": [
        {
          "ename": "MaxRetryError",
          "evalue": "HTTPSConnectionPool(host='controller.fed60dbd-6101-47c8-99d6-ab5cc1f62acf.pinecone.io', port=443): Max retries exceeded with url: /databases (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7fad49ede460>: Failed to resolve 'controller.fed60dbd-6101-47c8-99d6-ab5cc1f62acf.pinecone.io' ([Errno 8] nodename nor servname provided, or not known)\"))",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mraise\u001b[39;00m LocationParseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/socket.py:954\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    953\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 954\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[1;32m    955\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
            "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    490\u001b[0m         new_e \u001b[39m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mscheme)\n\u001b[0;32m--> 491\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\n\u001b[1;32m    493\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    468\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    612\u001b[0m server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connection.py:210\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7fad49ede460>: Failed to resolve 'controller.fed60dbd-6101-47c8-99d6-ab5cc1f62acf.pinecone.io' ([Errno 8] nodename nor servname provided, or not known)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 38\u001b[0m\n\u001b[1;32m     33\u001b[0m index_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnovel\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[39m# 持久化数据\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# docsearch = Pinecone.from_texts([t.page_content for t in split_docs], embeddings, index_name=index_name)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[39m# 加载数据\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m docsearch \u001b[39m=\u001b[39m Pinecone\u001b[39m.\u001b[39;49mfrom_existing_index(index_name,embeddings)\n\u001b[1;32m     40\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m孔乙己是谁？\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m docs \u001b[39m=\u001b[39m docsearch\u001b[39m.\u001b[39msimilarity_search(query, include_metadata\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/langchain/vectorstores/pinecone.py:437\u001b[0m, in \u001b[0;36mPinecone.from_existing_index\u001b[0;34m(cls, index_name, embedding, text_key, namespace, pool_threads)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_existing_index\u001b[39m(\n\u001b[1;32m    429\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m     pool_threads: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m,\n\u001b[1;32m    435\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Pinecone:\n\u001b[1;32m    436\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load pinecone vectorstore from index name.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     pinecone_index \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_pinecone_index(index_name, pool_threads)\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(pinecone_index, embedding, text_key, namespace)\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/langchain/vectorstores/pinecone.py:354\u001b[0m, in \u001b[0;36mPinecone.get_pinecone_index\u001b[0;34m(cls, index_name, pool_threads)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    350\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import pinecone python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install pinecone-client`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m     )\n\u001b[0;32m--> 354\u001b[0m indexes \u001b[39m=\u001b[39m pinecone\u001b[39m.\u001b[39;49mlist_indexes()  \u001b[39m# checks if provided index exists\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m index_name \u001b[39min\u001b[39;00m indexes:\n\u001b[1;32m    357\u001b[0m     index \u001b[39m=\u001b[39m pinecone\u001b[39m.\u001b[39mIndex(index_name, pool_threads\u001b[39m=\u001b[39mpool_threads)\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/pinecone/manage.py:185\u001b[0m, in \u001b[0;36mlist_indexes\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Lists all indexes.\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m api_instance \u001b[39m=\u001b[39m _get_api_instance()\n\u001b[0;32m--> 185\u001b[0m response \u001b[39m=\u001b[39m api_instance\u001b[39m.\u001b[39;49mlist_indexes()\n\u001b[1;32m    186\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/pinecone/core/client/api_client.py:776\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    766\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" This method is invoked when endpoints are called\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m    Example:\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m \n\u001b[1;32m    775\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallable(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/pinecone/core/client/api/index_operations_api.py:1132\u001b[0m, in \u001b[0;36mIndexOperationsApi.__init__.<locals>.__list_indexes\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_check_return_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1129\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m_check_return_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m )\n\u001b[1;32m   1131\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1132\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_with_http_info(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/pinecone/core/client/api_client.py:838\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m     header_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_client\u001b[39m.\u001b[39mselect_header_content_type(\n\u001b[1;32m    835\u001b[0m         content_type_headers_list)\n\u001b[1;32m    836\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m header_list\n\u001b[0;32m--> 838\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mcall_api(\n\u001b[1;32m    839\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mendpoint_path\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mhttp_method\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    840\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    841\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    842\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    843\u001b[0m     body\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    844\u001b[0m     post_params\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mform\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    845\u001b[0m     files\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    846\u001b[0m     response_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mresponse_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    847\u001b[0m     auth_settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mauth\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    848\u001b[0m     async_req\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39masync_req\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    849\u001b[0m     _check_type\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_check_return_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    850\u001b[0m     _return_http_data_only\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_return_http_data_only\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    851\u001b[0m     _preload_content\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_preload_content\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    852\u001b[0m     _request_timeout\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_request_timeout\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    853\u001b[0m     _host\u001b[39m=\u001b[39;49m_host,\n\u001b[1;32m    854\u001b[0m     collection_formats\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mcollection_format\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/pinecone/core/client/api_client.py:413\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__call_api(resource_path, method,\n\u001b[1;32m    414\u001b[0m                            path_params, query_params, header_params,\n\u001b[1;32m    415\u001b[0m                            body, post_params, files,\n\u001b[1;32m    416\u001b[0m                            response_type, auth_settings,\n\u001b[1;32m    417\u001b[0m                            _return_http_data_only, collection_formats,\n\u001b[1;32m    418\u001b[0m                            _preload_content, _request_timeout, _host,\n\u001b[1;32m    419\u001b[0m                            _check_type)\n\u001b[1;32m    421\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    422\u001b[0m                                                method, path_params,\n\u001b[1;32m    423\u001b[0m                                                query_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                                _request_timeout,\n\u001b[1;32m    432\u001b[0m                                                _host, _check_type))\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/pinecone/core/client/api_client.py:200\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    196\u001b[0m     url \u001b[39m=\u001b[39m _host \u001b[39m+\u001b[39m resource_path\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     response_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    201\u001b[0m         method, url, query_params\u001b[39m=\u001b[39;49mquery_params, headers\u001b[39m=\u001b[39;49mheader_params,\n\u001b[1;32m    202\u001b[0m         post_params\u001b[39m=\u001b[39;49mpost_params, body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    203\u001b[0m         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    204\u001b[0m         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout)\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/pinecone/core/client/api_client.py:439\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes the HTTP request using RESTClient.\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mGET(url,\n\u001b[1;32m    440\u001b[0m                                 query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    441\u001b[0m                                 _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    442\u001b[0m                                 _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    443\u001b[0m                                 headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    444\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mHEAD(url,\n\u001b[1;32m    446\u001b[0m                                  query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    447\u001b[0m                                  _preload_content\u001b[39m=\u001b[39m_preload_content,\n\u001b[1;32m    448\u001b[0m                                  _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    449\u001b[0m                                  headers\u001b[39m=\u001b[39mheaders)\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/pinecone/core/client/rest.py:236\u001b[0m, in \u001b[0;36mRESTClientObject.GET\u001b[0;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mGET\u001b[39m(\u001b[39mself\u001b[39m, url, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, query_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _preload_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    235\u001b[0m         _request_timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url,\n\u001b[1;32m    237\u001b[0m                         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    238\u001b[0m                         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    239\u001b[0m                         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    240\u001b[0m                         query_params\u001b[39m=\u001b[39;49mquery_params)\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/pinecone/core/client/rest.py:202\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[39mraise\u001b[39;00m ApiException(status\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, reason\u001b[39m=\u001b[39mmsg)\n\u001b[1;32m    200\u001b[0m     \u001b[39m# For `GET`, `HEAD`\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m         r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool_manager\u001b[39m.\u001b[39;49mrequest(method, url,\n\u001b[1;32m    203\u001b[0m                                       fields\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    204\u001b[0m                                       preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    205\u001b[0m                                       timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    206\u001b[0m                                       headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m urllib3\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mSSLError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    208\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(e)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mstr\u001b[39m(e))\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/_request_methods.py:110\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    107\u001b[0m     urlopen_kw[\u001b[39m\"\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m body\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_url_methods:\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_url(\n\u001b[1;32m    111\u001b[0m         method,\n\u001b[1;32m    112\u001b[0m         url,\n\u001b[1;32m    113\u001b[0m         fields\u001b[39m=\u001b[39;49mfields,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    114\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    115\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw,\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[1;32m    119\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m    120\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_url\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mif\u001b[39;00m fields:\n\u001b[1;32m    141\u001b[0m     url \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m urlencode(fields)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connectionpool.py:874\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn:\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Try again\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 874\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    875\u001b[0m         method,\n\u001b[1;32m    876\u001b[0m         url,\n\u001b[1;32m    877\u001b[0m         body,\n\u001b[1;32m    878\u001b[0m         headers,\n\u001b[1;32m    879\u001b[0m         retries,\n\u001b[1;32m    880\u001b[0m         redirect,\n\u001b[1;32m    881\u001b[0m         assert_same_host,\n\u001b[1;32m    882\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    883\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    884\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    885\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    886\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    887\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    888\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    889\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    893\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connectionpool.py:874\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn:\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Try again\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 874\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    875\u001b[0m         method,\n\u001b[1;32m    876\u001b[0m         url,\n\u001b[1;32m    877\u001b[0m         body,\n\u001b[1;32m    878\u001b[0m         headers,\n\u001b[1;32m    879\u001b[0m         retries,\n\u001b[1;32m    880\u001b[0m         redirect,\n\u001b[1;32m    881\u001b[0m         assert_same_host,\n\u001b[1;32m    882\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    883\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    884\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    885\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    886\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    887\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    888\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    889\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    893\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connectionpool.py:874\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn:\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Try again\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 874\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    875\u001b[0m         method,\n\u001b[1;32m    876\u001b[0m         url,\n\u001b[1;32m    877\u001b[0m         body,\n\u001b[1;32m    878\u001b[0m         headers,\n\u001b[1;32m    879\u001b[0m         retries,\n\u001b[1;32m    880\u001b[0m         redirect,\n\u001b[1;32m    881\u001b[0m         assert_same_host,\n\u001b[1;32m    882\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    883\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    884\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    885\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    886\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    887\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    888\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    889\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    893\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_e, (\u001b[39mOSError\u001b[39;00m, HTTPException)):\n\u001b[1;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n\u001b[1;32m    849\u001b[0m \u001b[39m# Keep track of the error for the retry warning.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m    514\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n\u001b[1;32m    519\u001b[0m \u001b[39mreturn\u001b[39;00m new_retry\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='controller.fed60dbd-6101-47c8-99d6-ab5cc1f62acf.pinecone.io', port=443): Max retries exceeded with url: /databases (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7fad49ede460>: Failed to resolve 'controller.fed60dbd-6101-47c8-99d6-ab5cc1f62acf.pinecone.io' ([Errno 8] nodename nor servname provided, or not known)\"))"
          ]
        }
      ],
      "source": [
        "import os;\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.vectorstores import Chroma, Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "import pinecone\n",
        "\n",
        "# 初始化 pinecone\n",
        "pinecone.init(\n",
        "  api_key=os.environ[\"PINECONE_API_KEY\"],\n",
        "  environment=os.environ[\"PINECONE_API_KEY\"],\n",
        ")\n",
        "\n",
        "loader = DirectoryLoader('./data', glob='**/*.txt')\n",
        "# 将数据转成 document 对象，每个文件会作为一个 document\n",
        "documents = loader.load()\n",
        "\n",
        "# 初始化加载器\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "# 切割加载的 document\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# 初始化 openai 的 embeddings 对象\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    deployment_name=\"text-embedding-ada-002\",\n",
        "    model_name=\"text-embedding-ada-002\",\n",
        "    chunk_size=1,\n",
        ")\n",
        "\n",
        "index_name=\"novel\"\n",
        "# 持久化数据\n",
        "# docsearch = Pinecone.from_texts([t.page_content for t in split_docs], embeddings, index_name=index_name)\n",
        "\n",
        "# 加载数据\n",
        "docsearch = Pinecone.from_existing_index(index_name,embeddings)\n",
        "\n",
        "query = \"孔乙己是谁？\"\n",
        "docs = docsearch.similarity_search(query, include_metadata=True)\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    max_tokens=1500,\n",
        "    temperature=0,\n",
        ")\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\", verbose=True)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhZGQ72NODIZ"
      },
      "source": [
        "# 使用GPT3.5模型构建油管频道问答机器人\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRan7KZ-MgBv",
        "outputId": "8d9100bc-daaa-42ef-f255-1dcb9ac062b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content=\"[Applause] thanks Tim and hi everyone I'm excited to get to show you some of the new experimental features we've been working on for Unreal Engine 5.2 let's take a look [Music] all right so last year we added several new features to the engine to support foliage rendering and the fortnite team uses features to ship battle royale chapter 4. at the same time Jacob over there and the team at qixel were experimenting with what's possible for photoreal foliage environments as well as testing out the latest functionality that we've been building for Unreal Engine so Jacob's here with us today in the unreal editor let's explore the environment and what better way to do that than off-roading and what better way to off-road than an arivian r1t now rivian uses unreal to power their instrument cluster including 3D visualization of their vehicles so we worked with them to bring the r1t to life in this experience let's head on out Jacob sure thing on my way all right so we're building tools for\", metadata={'source': 'Dj60HHy-Kqk'})]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "Use the following context to answer the user's question.\n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer. And answer in English.\n",
            "-----------\n",
            "[Applause] thanks Tim and hi everyone I'm excited to get to show you some of the new experimental features we've been working on for Unreal Engine 5.2 let's take a look [Music] all right so last year we added several new features to the engine to support foliage rendering and the fortnite team uses features to ship battle royale chapter 4. at the same time Jacob over there and the team at qixel were experimenting with what's possible for photoreal foliage environments as well as testing out the latest functionality that we've been building for Unreal Engine so Jacob's here with us today in the unreal editor let's explore the environment and what better way to do that than off-roading and what better way to off-road than an arivian r1t now rivian uses unreal to power their instrument cluster including 3D visualization of their vehicles so we worked with them to bring the r1t to life in this experience let's head on out Jacob sure thing on my way all right so we're building tools for\n",
            "\n",
            "complex materials for extremely detailed use cases like in cinematics and in film so we're going to drive under this fallen tree here and everything that you've seen up to this point was painstakingly hand built by the environment team at qixel everything since that fallen tree has been built using our brand new experimental Suite of procedural content generation tools entirely an engine that are flexible deterministic and artist driven our guiding principle in building these systems was to empower artists to make tools for artists so Jacob's going to go ahead and add a procedural assembly to the world and the cool thing is that it communicates thank you yeah pretty cool and the cool thing is that it communicates with other nearby procedural elements in the scene like the creek bed so let's say a designer comes by wants to direct the player to drive to the left Jacob can simply move the assembly to the right and everything updates to accommodate that change game design is iterative so\n",
            "\n",
            "building tools for interactive and dynamic worlds so here we have chaos physics simulating rocks that tumble as we drive over them leaves Bend out of the way and we also added some real-time fluid simulation we worked with the team at rivien to set up unreal's chaos vehicle model to simulate the suspension of the truck and how the electric motors Drive each individual wheel chaos also simulates how the tires compress and deform and meta sounds enabled the team to precisely re-synthesize the sounds of the electric motors and mix them with the ambisonics of the jungle so rivien provided us with a highly detailed model of the truck about 71 million polygons that were able to render in real time thanks to nanite now the rivian not only looks incredibly realistic because of lumen and nanite but also its materials and today we're introducing substrate our new material framework and the better demonstrate it let's swap the paint out for opal now of course you can't order a rivian with opal\n",
            "\n",
            "variability so the procedural systems are all deterministic as Jacob is experimenting with different sets of input parameters once he finds a set that he likes he can always go back to it and get out exactly the same results and the procedural systems aren't just placing trees and rocks but also fog cards bugs birds everything that's needed to bring this environment to life and everything that you've seen here works at scale this environment is four kilometers by four kilometers if we hide all the procedural elements we can see that original hand-built area about 200 meters by 200 meters we believe that there will always be the need for hand building environments so we design these procedural systems to be tools for artists that work in concert with hand-built content both substrate and the new procedural tools will be available in experimental form in 5.2 and everything you've seen here is running in the unreal editor in real time on a developer machine with an Intel 13900k CPU and\n",
            "-----------\n",
            "\n",
            "\n",
            "Human: 什么是 Unreal Engine\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Unreal Engine是一款由Epic Games开发的游戏引擎。它是一个强大的实时渲染和开发工具，用于创建高质量的游戏、虚拟现实和增强现实体验。Unreal Engine提供了一套丰富的功能和工具，包括图形渲染、物理模拟、动画、人工智能、音频、蓝图脚本和多平台支持等，使开发者能够创建出令人惊叹的游戏和虚拟现实应用。它被广泛应用于游戏开发、电影制作、建筑可视化、培训模拟等领域。\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: 什么是 Unreal Engine\n",
            "Assistant: Unreal Engine是一款由Epic Games开发的游戏引擎。它是一个强大的实时渲染和开发工具，用于创建高质量的游戏、虚拟现实和增强现实体验。Unreal Engine提供了一套丰富的功能和工具，包括图形渲染、物理模拟、动画、人工智能、音频、蓝图脚本和多平台支持等，使开发者能够创建出令人惊叹的游戏和虚拟现实应用。它被广泛应用于游戏开发、电影制作、建筑可视化、培训模拟等领域。\n",
            "Follow Up Input: Unreal Engine 版本是多少\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "Use the following context to answer the user's question.\n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer. And answer in English.\n",
            "-----------\n",
            "[Applause] thanks Tim and hi everyone I'm excited to get to show you some of the new experimental features we've been working on for Unreal Engine 5.2 let's take a look [Music] all right so last year we added several new features to the engine to support foliage rendering and the fortnite team uses features to ship battle royale chapter 4. at the same time Jacob over there and the team at qixel were experimenting with what's possible for photoreal foliage environments as well as testing out the latest functionality that we've been building for Unreal Engine so Jacob's here with us today in the unreal editor let's explore the environment and what better way to do that than off-roading and what better way to off-road than an arivian r1t now rivian uses unreal to power their instrument cluster including 3D visualization of their vehicles so we worked with them to bring the r1t to life in this experience let's head on out Jacob sure thing on my way all right so we're building tools for\n",
            "\n",
            "看看挂在提把上的木牌，牌上有植物图画，并且写了数字。\n",
            "\n",
            "猫猫拿起画有梅花，写着「壹七」的篮子后，脚步变成了小跑步。她想趁厚重乌云低垂的天空开始落雨之前赶回房间。\n",
            "\n",
            "猫猫抱起放在脚边的洗衣篮，前往建物背后。与门面相比下显得十分煞风景的中庭里，有一处地面铺石的水池，一群难以界定性别的仆人正在洗涤大量衣物。\n",
            "-----------\n",
            "\n",
            "Human: 什么是 Unreal Engine\n",
            "Assistant: Unreal Engine是一款由Epic Games开发的游戏引擎。它是一个强大的实时渲染和开发工具，用于创建高质量的游戏、虚拟现实和增强现实体验。Unreal Engine提供了一套丰富的功能和工具，包括图形渲染、物理模拟、动画、人工智能、音频、蓝图脚本和多平台支持等，使开发者能够创建出令人惊叹的游戏和虚拟现实应用。它被广泛应用于游戏开发、电影制作、建筑可视化、培训模拟等领域。\n",
            "\n",
            "Human: Unreal Engine的版本号是多少？\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "根据对话中的上下文，没有提到具体的版本号。因此，我不知道当前讨论的是哪个版本的Unreal Engine。\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: 什么是 Unreal Engine\n",
            "Assistant: Unreal Engine是一款由Epic Games开发的游戏引擎。它是一个强大的实时渲染和开发工具，用于创建高质量的游戏、虚拟现实和增强现实体验。Unreal Engine提供了一套丰富的功能和工具，包括图形渲染、物理模拟、动画、人工智能、音频、蓝图脚本和多平台支持等，使开发者能够创建出令人惊叹的游戏和虚拟现实应用。它被广泛应用于游戏开发、电影制作、建筑可视化、培训模拟等领域。\n",
            "Human: Unreal Engine 版本是多少\n",
            "Assistant: 根据对话中的上下文，没有提到具体的版本号。因此，我不知道当前讨论的是哪个版本的Unreal Engine。\n",
            "Follow Up Input: Unreal Engine 5.2 有什么功能\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "Use the following context to answer the user's question.\n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer. And answer in English.\n",
            "-----------\n",
            "[Applause] thanks Tim and hi everyone I'm excited to get to show you some of the new experimental features we've been working on for Unreal Engine 5.2 let's take a look [Music] all right so last year we added several new features to the engine to support foliage rendering and the fortnite team uses features to ship battle royale chapter 4. at the same time Jacob over there and the team at qixel were experimenting with what's possible for photoreal foliage environments as well as testing out the latest functionality that we've been building for Unreal Engine so Jacob's here with us today in the unreal editor let's explore the environment and what better way to do that than off-roading and what better way to off-road than an arivian r1t now rivian uses unreal to power their instrument cluster including 3D visualization of their vehicles so we worked with them to bring the r1t to life in this experience let's head on out Jacob sure thing on my way all right so we're building tools for\n",
            "\n",
            "看看挂在提把上的木牌，牌上有植物图画，并且写了数字。\n",
            "\n",
            "猫猫抱起放在脚边的洗衣篮，前往建物背后。与门面相比下显得十分煞风景的中庭里，有一处地面铺石的水池，一群难以界定性别的仆人正在洗涤大量衣物。\n",
            "\n",
            "variability so the procedural systems are all deterministic as Jacob is experimenting with different sets of input parameters once he finds a set that he likes he can always go back to it and get out exactly the same results and the procedural systems aren't just placing trees and rocks but also fog cards bugs birds everything that's needed to bring this environment to life and everything that you've seen here works at scale this environment is four kilometers by four kilometers if we hide all the procedural elements we can see that original hand-built area about 200 meters by 200 meters we believe that there will always be the need for hand building environments so we design these procedural systems to be tools for artists that work in concert with hand-built content both substrate and the new procedural tools will be available in experimental form in 5.2 and everything you've seen here is running in the unreal editor in real time on a developer machine with an Intel 13900k CPU and\n",
            "-----------\n",
            "\n",
            "Human: 什么是 Unreal Engine\n",
            "Assistant: Unreal Engine是一款由Epic Games开发的游戏引擎。它是一个强大的实时渲染和开发工具，用于创建高质量的游戏、虚拟现实和增强现实体验。Unreal Engine提供了一套丰富的功能和工具，包括图形渲染、物理模拟、动画、人工智能、音频、蓝图脚本和多平台支持等，使开发者能够创建出令人惊叹的游戏和虚拟现实应用。它被广泛应用于游戏开发、电影制作、建筑可视化、培训模拟等领域。\n",
            "Human: Unreal Engine 版本是多少\n",
            "Assistant: 根据对话中的上下文，没有提到具体的版本号。因此，我不知道当前讨论的是哪个版本的Unreal Engine。\n",
            "\n",
            "Human: Unreal Engine 5.2有哪些功能？\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "根据对话中的上下文，提到了一些 Unreal Engine 5.2 的实验性功能，包括支持植被渲染的新功能、用于创建逼真植被环境的实验性功能、用于构建环境的程序化系统工具等。然而，具体的功能列表没有在对话中提到。\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: 什么是 Unreal Engine\n",
            "Assistant: Unreal Engine是一款由Epic Games开发的游戏引擎。它是一个强大的实时渲染和开发工具，用于创建高质量的游戏、虚拟现实和增强现实体验。Unreal Engine提供了一套丰富的功能和工具，包括图形渲染、物理模拟、动画、人工智能、音频、蓝图脚本和多平台支持等，使开发者能够创建出令人惊叹的游戏和虚拟现实应用。它被广泛应用于游戏开发、电影制作、建筑可视化、培训模拟等领域。\n",
            "Human: Unreal Engine 版本是多少\n",
            "Assistant: 根据对话中的上下文，没有提到具体的版本号。因此，我不知道当前讨论的是哪个版本的Unreal Engine。\n",
            "Human: Unreal Engine 5.2 有什么功能\n",
            "Assistant: 根据对话中的上下文，提到了一些 Unreal Engine 5.2 的实验性功能，包括支持植被渲染的新功能、用于创建逼真植被环境的实验性功能、用于构建环境的程序化系统工具等。然而，具体的功能列表没有在对话中提到。\n",
            "Follow Up Input: \n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \n",
            "Use the following context to answer the user's question.\n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer. And answer in English.\n",
            "-----------\n",
            "[Applause] thanks Tim and hi everyone I'm excited to get to show you some of the new experimental features we've been working on for Unreal Engine 5.2 let's take a look [Music] all right so last year we added several new features to the engine to support foliage rendering and the fortnite team uses features to ship battle royale chapter 4. at the same time Jacob over there and the team at qixel were experimenting with what's possible for photoreal foliage environments as well as testing out the latest functionality that we've been building for Unreal Engine so Jacob's here with us today in the unreal editor let's explore the environment and what better way to do that than off-roading and what better way to off-road than an arivian r1t now rivian uses unreal to power their instrument cluster including 3D visualization of their vehicles so we worked with them to bring the r1t to life in this experience let's head on out Jacob sure thing on my way all right so we're building tools for\n",
            "\n",
            "variability so the procedural systems are all deterministic as Jacob is experimenting with different sets of input parameters once he finds a set that he likes he can always go back to it and get out exactly the same results and the procedural systems aren't just placing trees and rocks but also fog cards bugs birds everything that's needed to bring this environment to life and everything that you've seen here works at scale this environment is four kilometers by four kilometers if we hide all the procedural elements we can see that original hand-built area about 200 meters by 200 meters we believe that there will always be the need for hand building environments so we design these procedural systems to be tools for artists that work in concert with hand-built content both substrate and the new procedural tools will be available in experimental form in 5.2 and everything you've seen here is running in the unreal editor in real time on a developer machine with an Intel 13900k CPU and\n",
            "\n",
            "building tools for interactive and dynamic worlds so here we have chaos physics simulating rocks that tumble as we drive over them leaves Bend out of the way and we also added some real-time fluid simulation we worked with the team at rivien to set up unreal's chaos vehicle model to simulate the suspension of the truck and how the electric motors Drive each individual wheel chaos also simulates how the tires compress and deform and meta sounds enabled the team to precisely re-synthesize the sounds of the electric motors and mix them with the ambisonics of the jungle so rivien provided us with a highly detailed model of the truck about 71 million polygons that were able to render in real time thanks to nanite now the rivian not only looks incredibly realistic because of lumen and nanite but also its materials and today we're introducing substrate our new material framework and the better demonstrate it let's swap the paint out for opal now of course you can't order a rivian with opal\n",
            "\n",
            "complex materials for extremely detailed use cases like in cinematics and in film so we're going to drive under this fallen tree here and everything that you've seen up to this point was painstakingly hand built by the environment team at qixel everything since that fallen tree has been built using our brand new experimental Suite of procedural content generation tools entirely an engine that are flexible deterministic and artist driven our guiding principle in building these systems was to empower artists to make tools for artists so Jacob's going to go ahead and add a procedural assembly to the world and the cool thing is that it communicates thank you yeah pretty cool and the cool thing is that it communicates with other nearby procedural elements in the scene like the creek bed so let's say a designer comes by wants to direct the player to drive to the left Jacob can simply move the assembly to the right and everything updates to accommodate that change game design is iterative so\n",
            "-----------\n",
            "\n",
            "Human: 什么是 Unreal Engine\n",
            "Assistant: Unreal Engine是一款由Epic Games开发的游戏引擎。它是一个强大的实时渲染和开发工具，用于创建高质量的游戏、虚拟现实和增强现实体验。Unreal Engine提供了一套丰富的功能和工具，包括图形渲染、物理模拟、动画、人工智能、音频、蓝图脚本和多平台支持等，使开发者能够创建出令人惊叹的游戏和虚拟现实应用。它被广泛应用于游戏开发、电影制作、建筑可视化、培训模拟等领域。\n",
            "Human: Unreal Engine 版本是多少\n",
            "Assistant: 根据对话中的上下文，没有提到具体的版本号。因此，我不知道当前讨论的是哪个版本的Unreal Engine。\n",
            "Human: Unreal Engine 5.2 有什么功能\n",
            "Assistant: 根据对话中的上下文，提到了一些 Unreal Engine 5.2 的实验性功能，包括支持植被渲染的新功能、用于创建逼真植被环境的实验性功能、用于构建环境的程序化系统工具等。然而，具体的功能列表没有在对话中提到。\n",
            "\n",
            "Human: Unreal Engine 5.2 有哪些实验性功能？\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "根据对话中的上下文，提到了一些 Unreal Engine 5.2 的实验性功能，包括支持植被渲染的新功能、用于创建逼真植被环境的实验性功能、用于构建环境的程序化系统工具等。然而，具体的功能列表没有在对话中提到。\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import ChatVectorDBChain, ConversationalRetrievalChain\n",
        "\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "  ChatPromptTemplate,\n",
        "  SystemMessagePromptTemplate,\n",
        "  HumanMessagePromptTemplate\n",
        ")\n",
        "\n",
        "# 加载 youtube 频道\n",
        "loader = YoutubeLoader.from_youtube_url('https://www.youtube.com/watch?v=Dj60HHy-Kqk')\n",
        "# 将数据转成 document\n",
        "documents = loader.load()\n",
        "\n",
        "# 初始化文本分割器\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "  chunk_size=1000,\n",
        "  chunk_overlap=20\n",
        ")\n",
        "\n",
        "# 分割 youtube documents\n",
        "split_documents = text_splitter.split_documents(documents)\n",
        "print(split_documents[:1])\n",
        "\n",
        "# 初始化 openai embeddings\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    deployment_name=\"text-embedding-ada-002\",\n",
        "    model_name=\"text-embedding-ada-002\",\n",
        "    chunk_size=1,\n",
        ")\n",
        "\n",
        "# 将数据存入向量存储\n",
        "vector_store = Chroma.from_documents(split_documents, embeddings)\n",
        "# 通过向量存储初始化检索器\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "system_template = \"\"\"\n",
        "Use the following context to answer the user's question.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer. And answer in English.\n",
        "-----------\n",
        "{context}\n",
        "-----------\n",
        "{chat_history}\n",
        "\"\"\"\n",
        "\n",
        "# 构建初始 messages 列表，这里可以理解为是 openai 传入的 messages 参数\n",
        "messages = [\n",
        "  SystemMessagePromptTemplate.from_template(system_template),\n",
        "  HumanMessagePromptTemplate.from_template('{question}')\n",
        "]\n",
        "\n",
        "# 初始化 prompt 对象\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "\n",
        "# 初始化问答链\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    temperature=0.1,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    retriever,\n",
        "    combine_docs_chain_kwargs={\n",
        "        \"prompt\": prompt,\n",
        "    },\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "chat_history = []\n",
        "while True:\n",
        "  question = input('问题：')\n",
        "  # 开始发送问题 chat_history 为必须参数,用于存储对话历史\n",
        "  result = chain({'question': question, 'chat_history': chat_history})\n",
        "  chat_history.append((question, result['answer']))\n",
        "  print(result['answer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVApiSmm8ocW"
      },
      "source": [
        "# 用 OpenAI 连接万种工具"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qJp8wx3Q8tDH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gmail: Send Email\n",
            "A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \"get the latest email from my bank\" or \"send a slack message to the #general channel\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are ['Message_Text', 'Channel'], your instruction should be something like 'send a slack message to the #general channel with the text hello world'. Another example: if the params are ['Calendar', 'Search_Term'], your instruction should be something like 'find the meeting in my personal calendar at 3pm'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say 'not enough information provided in the instruction, missing <param>'. If you get a none or null response, STOP EXECUTION, do not try to another tool!This tool specifically used for: Gmail: Send Email, and has params: ['To', 'Body', 'Subject', 'Cc']\n",
            "\n",
            "\n",
            "\n",
            "Gmail: Find Email\n",
            "A wrapper around Zapier NLA actions. The input to this tool is a natural language instruction, for example \"get the latest email from my bank\" or \"send a slack message to the #general channel\". Each tool will have params associated with it that are specified as a list. You MUST take into account the params when creating the instruction. For example, if the params are ['Message_Text', 'Channel'], your instruction should be something like 'send a slack message to the #general channel with the text hello world'. Another example: if the params are ['Calendar', 'Search_Term'], your instruction should be something like 'find the meeting in my personal calendar at 3pm'. Do not make up params, they will be explicitly specified in the tool description. If you do not have enough information to fill in the params, just say 'not enough information provided in the instruction, missing <param>'. If you get a none or null response, STOP EXECUTION, do not try to another tool!This tool specifically used for: Gmail: Find Email, and has params: ['Search_String']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.agents.agent_toolkits import ZapierToolkit\n",
        "from langchain.utilities.zapier import ZapierNLAWrapper\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    temperature=.3,\n",
        ")\n",
        "\n",
        "zapier = ZapierNLAWrapper()\n",
        "toolkit = ZapierToolkit.from_zapier_nla_wrapper(zapier)\n",
        "agent = initialize_agent(toolkit.get_tools(), llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# 我们可以通过打印的方式看到我们都在 Zapier 里面配置了哪些可以用的工具\n",
        "for tool in toolkit.get_tools():\n",
        "  print (tool.name)\n",
        "  print (tool.description)\n",
        "  print (\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "O-r5lPuV9j_1",
        "outputId": "a43e51ee-d7ad-4d6a-b4ef-9a95c414bb48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to send an email to the specified recipient with the given content.\n",
            "Action: Gmail: Send Email\n",
            "Action Input: To: \"lilong7676@outlook.com\", Body: \"Hello from LangChain World\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{\"id\": \"18a98301462f9429\", \"threadId\": \"18a98301462f9429\", \"labelIds\": [\"SENT\"]}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have successfully sent the email to the recipient.\n",
            "Final Answer: The email has been sent to \"lilong7676@outlook.com\" with the content \"Hello from LangChain World\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The email has been sent to \"lilong7676@outlook.com\" with the content \"Hello from LangChain World\".'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run('请发送一封邮件给\"lilong7676@outlook.com\"，内容是\"Hello from LangChain World\"。')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDdWamdTIw4-"
      },
      "source": [
        "# 一些有意思的小Tip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bUGvgAqJfkt"
      },
      "source": [
        "## 执行多个chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQFxSP3rJlHF",
        "outputId": "2f2c8d3a-0787-4f00-aaa5-1b0d1f274710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mOne classic dish from China is Peking Duck. Peking Duck is a dish that originated in Beijing and is considered one of the most famous dishes in Chinese cuisine. It is made by roasting a whole duck until the skin is crispy and golden while the meat remains tender and juicy. The duck is traditionally served with thin pancakes, spring onions, cucumber, and hoisin sauce. This dish is not only delicious but also showcases the skill and artistry of Chinese cuisine.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mIngredients:\n",
            "- 1 whole duck\n",
            "- Salt\n",
            "- 1 tablespoon honey\n",
            "- 1 tablespoon soy sauce\n",
            "- 1 tablespoon rice wine or dry sherry\n",
            "- Thin pancakes or tortillas\n",
            "- Spring onions\n",
            "- Cucumber\n",
            "- Hoisin sauce\n",
            "\n",
            "Instructions:\n",
            "1. Preheat your oven to 350°F (175°C).\n",
            "2. Clean the duck thoroughly and pat it dry.\n",
            "3. Rub the inside and outside of the duck with salt to season.\n",
            "4. Place the duck on a rack in a roasting pan, breast side up.\n",
            "5. Roast the duck for approximately 3 hours, or until the skin is crispy and golden. \n",
            "6. While the duck is roasting, prepare the glaze by combining the honey, soy sauce, and rice wine or sherry in a small bowl.\n",
            "7. After the duck has been roasting for about 2 hours, brush the glaze over the skin every 15 minutes to add flavor and enhance the crispiness. \n",
            "8. Once the duck is cooked, remove it from the oven and let it rest for a few minutes.\n",
            "9. Carve the duck into thin slices, separating the skin from the meat.\n",
            "10. Serve the sliced duck with thin pancakes, thinly sliced spring onions, cucumber, and hoisin sauce.\n",
            "11. To enjoy, place a slice of duck skin, a slice of meat, some spring onions, cucumber, and hoisin sauce onto a pancake, roll it up, and enjoy the tasty and authentic Peking Duck experience.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "# location 链\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    temperature=1,\n",
        ")\n",
        "\n",
        "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n",
        "% USER LOCATION\n",
        "{user_location}\n",
        "\n",
        "YOUR RESPONSE:\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
        "location_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "# meal 链\n",
        "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
        "% MEAL\n",
        "{user_meal}\n",
        "\n",
        "YOUR RESPONSE:\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
        "meal_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "# 通过 SimpleSequentialChain 串联起来，第一个答案会被替换第二个中的user_meal，然后再进行询问\n",
        "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)\n",
        "review = overall_chain.run(\"China\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QVu6_HVJTlW"
      },
      "source": [
        "## 结构化输出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwEocODtt5Tm",
        "outputId": "b0d23eb5-6253-4bc5-990f-f798fe19a7b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bad_string': 'hello wolrd!', 'good_string': 'hello world!'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    temperature=1,\n",
        ")\n",
        "\n",
        "# 告诉他我们生成的内容需要哪些字段，每个字段类型式啥\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
        "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
        "]\n",
        "\n",
        "# 初始化解析器\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "\n",
        "# 生成的格式提示符\n",
        "# {\n",
        "#\t\"bad_string\": string  // This a poorly formatted user input string\n",
        "#\t\"good_string\": string  // This is your response, a reformatted response\n",
        "#}\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "template = \"\"\"\n",
        "You will be given a poorly formatted string from a user.\n",
        "Reformat it and make sure all the words are spelled correctly\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "% USER INPUT:\n",
        "{user_input}\n",
        "\n",
        "YOUR RESPONSE:\n",
        "\"\"\"\n",
        "\n",
        "# 讲我们的格式描述嵌入到 prompt 中去，告诉 llm 我们需要他输出什么样格式的内容\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"user_input\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        "    template=template\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "llm_output = chain.run(\"hello wolrd!\")\n",
        "\n",
        "# 使用解析器进行解析生成的内容\n",
        "output_parser.parse(llm_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00kLaQZWS-Jq"
      },
      "source": [
        "## 爬取网页并输出JSON数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAkS_wX8IaA1",
        "outputId": "20006363-6a63-407c-aacc-5be7033af1d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"company_name\":\"贵州茅台酒股份有限公司\",\n",
            "  \"company_english_name\":\"Kweichow Moutai Co.,Ltd.\",\n",
            "  \"issue_price\":\"31.39\",\n",
            "  \"date_of_establishment\":\"1999-11-20\",\n",
            "  \"registered_capital\":\"125620万元(CNY)\",\n",
            "  \"office_address\":\"贵州省仁怀市茅台镇\",\n",
            "  \"Company_profile\":\"公司是根据贵州省人民政府黔府函〔1999〕291号文,由中国贵州茅台酒厂有限责任公司作为主发起人,联合贵州茅台酒厂技术开发公司、贵州省轻纺集体工业联社、深圳清华大学研究院、中国食品发酵工业研究院、北京市糖业烟酒公司、江苏省糖烟酒总公司、上海捷强烟草糖酒(集团)有限公司于1999年11月20日共同发起设立的股份有限公司。经中国证监会证监发行字[2001]41号文核准并按照财政部企[2001]56号文件的批复,公司于2001年7月31日在上海证券交易所公开发行7,150万(其中,国有股存量发行650万股)A股股票。\",\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMRequestsChain, LLMChain\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "template = \"\"\"在 >>> 和 <<< 之间是网页的返回的HTML内容。\n",
        "网页是新浪财经A股上市公司的公司简介。\n",
        "请抽取参数请求的信息。\n",
        "\n",
        ">>> {requests_result} <<<\n",
        "请使用如下的JSON格式返回数据\n",
        "{{\n",
        "  \"company_name\":\"a\",\n",
        "  \"company_english_name\":\"b\",\n",
        "  \"issue_price\":\"c\",\n",
        "  \"date_of_establishment\":\"d\",\n",
        "  \"registered_capital\":\"e\",\n",
        "  \"office_address\":\"f\",\n",
        "  \"Company_profile\":\"g\"\n",
        "\n",
        "}}\n",
        "Extracted:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"requests_result\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "chain = LLMRequestsChain(llm_chain=LLMChain(llm=llm, prompt=prompt))\n",
        "inputs = {\n",
        "  \"url\": \"https://vip.stock.finance.sina.com.cn/corp/go.php/vCI_CorpInfo/stockid/600519.phtml\"\n",
        "}\n",
        "\n",
        "response = chain(inputs)\n",
        "print(response['output'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dh9Zxt6NqAY"
      },
      "source": [
        "## 自定义工具"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "IHMHz8vfNs6w",
        "outputId": "b6ce681a-3eed-4e69-95ad-6fa76ee7429e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out today's date and the date of this year's National Day.\n",
            "Action: Search\n",
            "Action Input: \"today's date\" and \"date of this year's National Day\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Friday, September 15th.']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have found today's date, but I still need to find the date of this year's National Day.\n",
            "Action: Search\n",
            "Action Input: \"date of this year's National Day\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Friday, September 15th. Day of the year 258. Week of the year 37. 2023. 71% ... Stay up to date on upcoming national days and Celebrate Every Day! Type your ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have found the date of this year's National Day.\n",
            "Action: WriteToFile\n",
            "Action Input: \"Friday, September 15th.\"\u001b[0mText appended to './output/summary_content.txt' successfully.\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mNone\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Today's date is September 15th. The date of this year's National Day is also September 15th.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Today's date is September 15th. The date of this year's National Day is also September 15th.\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import LLMMathChain, SerpAPIWrapper\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 初始化搜索链和计算链\n",
        "search = SerpAPIWrapper()\n",
        "llm_math_chain = LLMMathChain(llm=llm, verbose=True)\n",
        "\n",
        "\n",
        "FILE_NAME = \"./output/summary_content.txt\"\n",
        "\n",
        "def append_text_to_file(text):\n",
        "    try:\n",
        "        # Open the file in 'a' mode (append mode) which creates the file if it doesn't exist\n",
        "        with open(FILE_NAME, 'a') as file:\n",
        "            file.write(text + '\\n') # Append the text to the file\n",
        "        print(f\"Text appended to '{FILE_NAME}' successfully.\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# 生成一个功能列表，指明这个 agent 里面都有哪些可用工具\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=llm_math_chain.run,\n",
        "        description=\"useful for when you need to answer questions about math\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"WriteToFile\",\n",
        "        func=append_text_to_file,\n",
        "        description=\"useful when you need to write any text in the file.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# 初始化 agent\n",
        "system_message = SystemMessage(content=\"Your role is to answer the user's questions in a human-like manner. Please respond in Chinese\")\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    system_message=system_message,\n",
        "    agent_kwargs={\n",
        "        \"system_message\": system_message\n",
        "    },\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 执行 agent\n",
        "agent.run(\"今天日期是什么？今年国庆啥时间？请把答案写到文件当中\")\n",
        "# agent.run(\"12 的 12 次方是多少？\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOIICEUZvjR0"
      },
      "source": [
        "## 使用Memory实现一个带记忆的对话机器人"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qG5EGbpviKl",
        "outputId": "d58d85ac-5e4a-44e1-8a8c-31bb0b950e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='中国的首都是北京。' additional_kwargs={} example=False\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-35-turbo-16k\",\n",
        "    model_name=\"gpt-35-turbo-16k\",\n",
        "    temperature=1,\n",
        ")\n",
        "\n",
        "# 初始化 MessageHistory 对象\n",
        "history = ChatMessageHistory()\n",
        "\n",
        "# 给 MessageHistory 对象添加对话内容\n",
        "history.add_ai_message(\"你好！\")\n",
        "history.add_user_message(\"中国的首都是哪里？\")\n",
        "\n",
        "# 执行对话\n",
        "ai_response = llm(history.messages)\n",
        "print(ai_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "zghoJNCmGAQY",
        "Ao78SDEp1Xbf",
        "j0-Zs6KZ6Dgi",
        "L1nWOkGvCStj",
        "NySCEE0-tKw-",
        "7gGjGMljB24P",
        "dhZGQ72NODIZ",
        "2dh9Zxt6NqAY"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
